<!--- SPDX-License-Identifier: Apache-2.0 -->

# Wed Nov 9, 2022 at 8:00am PDT

## Agenda
* Exporting preprocessing to ONNX
* ONNX <-> DALI
* Open floor

## Atendees
* Joaquin Anton (NVIDIA)
* Natalie Kershaw (Microsoft)
* Ganesan Ramalingan (Microsoft)
* Xavier Dupre (Microsoft)
* Janusz Lisiecki (NVIDIA)
* Gabriel Esteves (Intel)

## Recording & Slides

* [Meeting Recording](https://lists.lfaidata.foundation/g/onnx-wg-preprocessing/files/onnx_preprocessing_20221109.mp4)
* [Meeting Slides](slides/20221109_slides.pdf)

## Meeting notes:

### Exporting preprocessing to ONNX

Reiterated on the problem of converting preprocessing from different FWs to ONNX

Two main challenges:
- Custom code
- high variety of external libraries processing the raw signal, with no common language

Natalie introduced the work done in [onnxruntime-extensions] to pre-generate pre and post processing to most common models:
https://github.com/microsoft/onnxruntime-extensions/pull/312/files#diff-8fd48c1c9e5277ce39cdaac456d4cd3a3854b0b0aebf318769ed2afc3d010e0a

At the moment the only solution is writing the preprocessing steps directly in ONNX format.

### ONNX <-> DALI

Joaquin introduced [NVIDIA DALI](https://github.com/NVIDIA/DALI), a library for data loading and preprocessing.

DALI uses a similar graph representation that would allow converting back and forth to ONNX.

DALI can be integrated with most common Deep Learning frameworks (PyTorch, Tensorflow, MXNet, Paddle) and DeepLearningExamples showcase DALI implementations for the data pipelines. This could be also used as a source for generating preprocessing ONNX models.

We discussed the possibility to start onnx-dali and dali-onnx repositories in ONNX. We agreed the best is to come up with a prototype first and then bring it up with the Steering Committee.

### Open floor

## Action items
