<!--- SPDX-License-Identifier: Apache-2.0 -->

# Wed Oct 13, 2021 at 3:00pm UTC

## Agenda
* The problem (Recap)
* Operator support
* Proof of concept (ResNet 50)
* Roadmap (Proposal)
* Data preprocessing within ONNX model

## Atendees
* Joaquin Anton
* Janusz L
* nakaike@jp.ibm.com
* Jacky Chen
* Rodolfo Gabriel Esteves
* Konstantinos Karanasos
* Rama

## Recording & Slides

* [Meeting Recording](https://lists.lfaidata.foundation/g/onnx-wg-preprocessing/files/onnx_preprocessing_20211013.mp4)
* [Slides](slides/20211013_slides.pdf)

## Meeting notes:

We recapped on the previous discussion about the problem that the WG wants to solve:
* Lack of standardized definitions of preprocessing primitives (portability issues).
* Difficulty to deploy pre-trained models to optimized environments because the preprocessing pipeline is typically defined with Python libraries (OpenCV, Numpy).

As a follow up to the last meeting, we discussed the initial set of operators that we want to initially supportL
* Joaquin suggestion is to initially cover ResNet/ResNext, SSD, and Mask R-CNN use cases. Some extensions are required to Resize operator, and a new operator for color space conversion might be required.
* Image decoding is also tricky, particularly for JPEG, as the decoding steps are not well defined and different libraries implement it differently. This is out of scope for the first prototype, but it should be considered later.
* Konstantinos raised the point of whether we should include data loading and file format parsing: reading from CSV, from database, etc. We agreed to leave it out of scope for the initial solution, but keep in mind. Konstantinos will check whether there are any particular use cases that will benefit from it and if so, we can decide to focus on data loading as well.

Joaquin showed a RN50 example changing the preprocessing step (using Numpy/Pillow) with a second ONNX Inference session:
* This serves as a proof-of-concept.
* Gabriel raised the importance of keeping the preprocessing pipeline identifiable within the model.

We discussed on the roadmap we want to follow, and agreed on two points:
* Determine the general architecture of how to include preprocessing definition in ONNX.
* Extend and add necessary operators to cover the most common applications. Cover first computer vision domain, and move to other domains (e.g. audio) later.
Those two are orthogonal problems and could be tackled separately.

We discussed the approach to include data preprocessing within an ONNX model:
* Joaquin suggested to extend the model definition with a second "preprocessing" graph. Later we could run preprocessing independently from the model, but within the same inference session
* Joaquin suggested to leave batchification as an implicit step left to the implementation, and not expressed explicitly in the batch.
* Gabe raised the point that having two steps (preprocessing and model run) will introduce optimization constraints. By having separate steps we would lose the ability of fusing operators at the boundary between data preprocessing and inference.
* Joaquin mentioned that the model and the preprocessing stages work with data that is different in nature. The model typically gets uniform batch with a particular shape, while the preprocessing stage has several samples of arbitrary shapes.
* Rama suggested that we keep preprocessing as part of the run call.
* Janusz raised the problem that if we totally merge the preprocessing graph with the model it will be harder to run preprocessing on a data processing specialized backend. If we manage to keep the preprocessing graph separately, we can still do that.
* Rama suggested to use sequence of tensors to represent the unprocessed samples at the end of the graph.
* Rama mentioned that adding a second graph to the model definition introduces significant changes to the protobuf definition of the model. Alternatively, we could two separate models (not graphs), that we combine with some utility.
* Rama suggested to introduce a special control flow operator accepting a sequence of tensors, applying the same preprocessing graph for each sample, and concatenate the preprocessed samples at the end. At the end the combined model has an extra "Preprocess" node with the preprocessing graph as an attribute.
* Joaquin mentioned that we should keep the ability to store the model and the preprocessing separately, so that the user has the ability to choose a preprocessing definition.
* Konstantinos suggested we can pass two separate ONNX models (preprocessing and the network) to the inference session, and the runtime would be in charge of combining them. The preprocessing model might include the special control flow operator, or be implicit. Two models could still be combined by a utility if needed.

## Conclusions:
* We agreed to distribute the preprocessing model separately.
* We will investigate more on the different solutions and choose the one that is less intrusive to the IR (proto definitions) concerns
